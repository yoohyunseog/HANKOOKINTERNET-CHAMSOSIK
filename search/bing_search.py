"""
Bing ê²€ìƒ‰ ëª¨ë“ˆ
"""

import requests
from urllib.parse import quote
from bs4 import BeautifulSoup
from typing import List, Dict
import re


def search_bing(keyword: str, search_type: str = 'web') -> str:
    """
    Bing ê²€ìƒ‰ URL ìƒì„±
    
    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        search_type: ê²€ìƒ‰ ìœ í˜• ('web', 'news', 'image', 'video')
    
    Returns:
        ê²€ìƒ‰ URL
    """
    encoded_keyword = quote(keyword)
    
    url_map = {
        'web': f'https://www.bing.com/search?q={encoded_keyword}',
        'news': f'https://www.bing.com/news/search?q={encoded_keyword}',
        'image': f'https://www.bing.com/images/search?q={encoded_keyword}',
        'video': f'https://www.bing.com/videos/search?q={encoded_keyword}'
    }
    
    return url_map.get(search_type, url_map['web'])


def get_bing_results(keyword: str, search_type: str = 'web', limit: int = 5) -> List[Dict]:
    """
    Bing ê²€ìƒ‰ ê²°ê³¼ í¬ë¡¤ë§
    
    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        search_type: ê²€ìƒ‰ ìœ í˜• ('web', 'news', 'image', 'video')
        limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [{'title': '', 'description': '', 'url': '', 'date': ''}, ...]
    """
    url = search_bing(keyword, search_type)
    results = []
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        }
        
        print(f"[Bing ê²€ìƒ‰] {search_type} '{keyword}' ê²€ìƒ‰ ì‹œì‘...")
        print(f"[URL] {url[:80]}...")
        
        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Bing ì›¹ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
        if search_type == 'web':
            print(f"[íŒŒì‹±] ì›¹ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± ì¤‘...")
            items = soup.select('.b_algo')
            print(f"[ê²°ê³¼] {len(items)}ê°œ ë°œê²¬")
            
            items = items[:limit]
            
            for idx, item in enumerate(items, 1):
                try:
                    title_elem = item.select_one('h2 a')
                    desc_elem = item.select_one('.b_snippet')
                    
                    if not title_elem:
                        continue
                    
                    title_text = title_elem.get_text(strip=True)
                    desc_text = desc_elem.get_text(strip=True) if desc_elem else ''
                    url_link = title_elem.get('href', '')
                    
                    if title_text and url_link:
                        results.append({
                            'title': title_text,
                            'description': desc_text,
                            'url': url_link,
                            'date': '',
                            'source': 'Bing'
                        })
                        print(f"[{idx}] {title_text[:60]}...")
                
                except Exception as e:
                    print(f"[ì˜¤ë¥˜] í•­ëª© íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
        
        # Bing ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
        elif search_type == 'news':
            print(f"[íŒŒì‹±] ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± ì¤‘...")
            items = soup.select('.news-card')
            print(f"[ê²°ê³¼] {len(items)}ê°œ ë°œê²¬")
            
            items = items[:limit]
            
            for idx, item in enumerate(items, 1):
                try:
                    title_elem = item.select_one('a.title')
                    desc_elem = item.select_one('.snippet')
                    date_elem = item.select_one('.source, span.update-time')
                    
                    if not title_elem:
                        continue
                    
                    title_text = title_elem.get_text(strip=True)
                    desc_text = desc_elem.get_text(strip=True) if desc_elem else ''
                    url_link = title_elem.get('href', '')
                    date_text = date_elem.get_text(strip=True) if date_elem else ''
                    
                    if title_text and url_link:
                        results.append({
                            'title': title_text,
                            'description': desc_text,
                            'url': url_link,
                            'date': date_text,
                            'source': 'Bing News'
                        })
                        print(f"[{idx}] {title_text[:60]}...")
                
                except Exception as e:
                    print(f"[ì˜¤ë¥˜] í•­ëª© íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
        
        else:
            print(f"[ì •ë³´] {search_type} ê²€ìƒ‰ì€ URL ì œê³µë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            results.append({
                'title': f'"{keyword}" Bing {search_type} ê²€ìƒ‰',
                'description': f'Bingì—ì„œ "{keyword}"ì˜ {search_type} ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.',
                'url': url,
                'date': '',
                'source': f'Bing {search_type}'
            })
        
    except Exception as e:
        print(f"[ì˜¤ë¥˜] Bing ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ URLì€ ì œê³µ
        results.append({
            'title': f'"{keyword}" Bing ê²€ìƒ‰',
            'description': f'Bing ê²€ìƒ‰ ë§í¬: {str(e)[:50]}',
            'url': url,
            'date': '',
            'source': 'Bing'
        })
    
    return results


def format_bing_results(results: List[Dict]) -> str:
    """
    Bing ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
    
    Args:
        results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    if not results:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    output = []
    for i, result in enumerate(results, 1):
        output.append(f"\n{i}. ğŸ” {result['title']}")
        if result.get('description'):
            output.append(f"   ğŸ“ {result['description']}")
        if result.get('date'):
            output.append(f"   ğŸ“… {result['date']}")
        if result.get('url'):
            output.append(f"   ğŸ”— {result['url']}")
    
    return '\n'.join(output)
